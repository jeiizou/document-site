---
slug: /DataStructureAndAlgorithm/CommonFormulasAndTheorems
---

# 常见公式和定理

## 贝叶斯定理

> Bayes' theorem : 描述在已知一些条件下, 某事件发生的概率. 
> 通常, 事件A在事件B已发生的条件下发生的概率, 与事件B在事件A已发生的条件下的概率是不一样的.
> 并且这两者是有确定的关系的, 贝叶斯定理就是这种关系的陈述.
> 贝叶斯公式的一个用途, 即投过已知的三个概率而推出第四个概率.
> 贝叶斯定理跟随机变量的条件概率以及边际概率分布有关

### 公式

$$
P(A|B) = \frac{P(A)P(B|A)}{P(B)}
$$

其中: 
- A, B为随机事件, P(B)不为0, P(A|B)是指在事件B发生的情况下事件A发生的概率
- `P(A|B)`是已知B发生后, A的条件概率, 也叫A的事后概率
- `P(A)`是A的先验概率(不考虑任何B方面的因素)
- `P(B|A)`是已知A发生后, B的条件概率, 也叫B的后验概率. 后时候叫: `在特定B时, A的似然性`
- `P(B)`是B的先验概率

按术语, 我们可以将贝叶斯定理表述为:

```
后验概率 = (似然性 * 先验概率) / 标准化常量
```

## 最小二乘法

最小二乘法, 又称最小平方发, 是一种数学优化建模的方法.

通过最小化误差的平方和寻找最佳函数匹配.

### 示例

某次实验得到了四个数据点`(x, y)`: `(1, 6)`, `(2, 5)`, `(3, 7)`, `(4, 10)`

我们希望找到一条和这四个点最匹配的直线: $y = \beta_1 + \beta_2x$.

即在某种"最佳状况"下能大致符合如下超定线性方程组的$\beta_1$和$\beta_2$:

![](imgs/2023-02-16-17-19-47.png)

最小二乘法采用的方法是尽量是的等号两边的平方差最小, 也就是找出这个函数的最小值:

![](imgs/2023-02-16-17-20-24.png)

最小值可以通过对$S(\beta_1, \beta_2)$分别求$\beta_1$和$\beta_2$的偏导数, 然后使其等于0得到:

![](imgs/2023-02-16-17-21-33.png)

如此, 我们可以解出: $\beta_1 = 3.5$, $\beta_2 = 1.4$, 即:

![](imgs/2023-02-16-17-22-24.png)

是最佳的. 

### 通用描述

当我们对于两个相关量感兴趣(弹簧与形变, 盈利与营业额, 投资收益与原始资本), 为了求得这些量同y之间的关系, 就用不相关变量去构建y, 我们使用一个函数模型:

![](imgs/2023-02-16-17-23-38.png)

`q`各独立变量或者`p`个系数进行拟合.

我们将这个函数类型称作函数模型. 

最小化问题的精度, 依赖于所选择的函数模型

## 马尔科夫链

马尔科夫链, 又称离散时间马尔科夫链(DTMC), 描述状态空间中经过从一个状态到另一个状态的转换的随机过程.

这个过程要求具备"无记忆"的性质: 下一状态的概率分布只能由当前状态决定, 在事件序列中, 它前面的时间均与之无关.

这种特定类型的"无记忆性"称作"马尔科夫性质".

在马尔科夫链的每一步, 系统根据概率分布, 可以从一个状态变到另一个状态. 

状态的改变叫转移, 与不同的状态改变相关的概率叫做转移概率.

随机满足就是马尔科夫链的例子. 随机漫步中每一步的状态是在图形中的点, 每衣服可以移动到任何一个相邻的点, 在这里移动到每一个点的概率都是相同的. 

### 形式化定义

马尔科夫链是满足马尔科夫性质的随机变量序列$X_1$, $X_2$, $X_3$, ..., 即给出当前状态, 将来状态和过去状态是相互独立的. 从形式上看:

如果两边的条件分布有定义, 即如果

$$
P_r(X_1 = x_1, ..., X_n = x_n), 则 P_r(X_{n+1} = x | X_1 = x_1, X_2=x_2,...,X_n=x_n) = P_r(X_{n+1}|X_n = x_n)
$$

`X`可能值构成的可数集`S`叫做改链的"状态空间".

通常通用一些列有向图来描述马尔科夫链, 其中图n的边用时刻`n`的状态到时刻`n+1`状态的概率$P_r(X_{n+1}|X_n = x_n)$来标记. 

也可以用这两个时刻之间的转移矩阵来表示同样的信息. 但是马氏链通常被假定为时齐的, 在这种情况下, 图和矩阵与n无关, 因此也不表现为序列.

## 感知器
a
感知器是一种最简单形式的前馈神经网络, 是一种二元线性分类器.

感知机是生物神经细胞的简单抽象.

神经细胞的结构大致可以分成: 树突, 突触, 细胞体和轴突. 单个神经细胞可以被视为一种只有两个状态的机器, 激动是为"是", 未激动是为"否".

### 定义

感知器是使用特征向量来表示的前馈神经网络, 是一种二元分类器, 把矩阵上的输入`x`映射到输出值`f(x)`上.

![](imgs/2023-02-16-17-54-22.png)

$w$是实数的表示权重的向量, $w\cdot{x}$是点积, $b$是偏置, 是一个不依赖于任何输入值的常数. 偏置可以认为是激励函数的偏移量, 或者给神经元一个基础活跃等级.

$f(x)$用于对x进行分类, 看他是肯定的还是否定的, 这属于二元分类问题. 如果`b`是负的, 那么加权后的输入必须产生一个肯定的值并且大于`-b`, 这样才能令分类神经元大于阈值0.

从空间上看, 偏置改变了决策边界的位置, 由于输入直接经过权重关系转换为输出, 所以感知器可以被视为最简单形式的前馈人工神经网络.


## 参考链接

- [贝叶斯定理](https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86)
- [最小二乘法](https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95)
- [马尔科夫链](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE)
- [感知器](https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8)